{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9ca3c80",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "## Titanic Data - Decision Tree\n",
    "- Determine baseline and baseline accuracy.\n",
    "- Split data, fit decision tree classifier to data.\n",
    "- Make predictions.\n",
    "- Get model score for training dataset.\n",
    "- Print confusion matrix and classification report for predictions.\n",
    "- Fit new model and run analysis for a different max_tree depth.\n",
    "- Determine which model performs better on in-sample data.\n",
    "- Determine which model performs better on out-of-sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff6f7c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports ###\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from env import get_db_url\n",
    "import explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c267f63c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "\n",
       "  embarked  class  deck  embark_town  alone  \n",
       "0        S  Third  None  Southampton      0  \n",
       "1        C  First     C    Cherbourg      0  \n",
       "2        S  Third  None  Southampton      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Pull titanic_db data ###\n",
    "url = get_db_url(db_name='titanic_db')\n",
    "df = pd.read_sql('SELECT * FROM passengers', url)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecb4ee76",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save a copy of dataframe before manipulations ###\n",
    "df_original = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab941bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((498, 13), (214, 13), (179, 13))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Split data ###\n",
    "train_validate, test = train_test_split(df, test_size=.2, \n",
    "                                            random_state=123, \n",
    "                                            stratify=df.survived)\n",
    "train, validate = train_test_split(train_validate, test_size=.3,\n",
    "                                                   random_state=123,\n",
    "                                                   stratify=train_validate.survived)\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c897a870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6164658634538153"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Baseline and Baseline Prediction ###\n",
    "# train.survived.value_counts()\n",
    "(train.survived == 0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5313e0",
   "metadata": {},
   "source": [
    "Data is tidy, continuing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e8e1483",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bivariate Exploration setup ###\n",
    "cat_vars = ['pclass', 'sex', 'deck', 'embark_town', 'alone']\n",
    "quant_vars = ['age', 'sibsp', 'parch', 'fare']\n",
    "target = 'survived'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a536ebcc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Bivariate Exploration ###\n",
    "# explore.explore_bivariate(train, target, cat_vars, quant_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b295b38",
   "metadata": {},
   "source": [
    "Candidates for model:\n",
    "- Sex\n",
    "- Fare\n",
    "- Passenger Class\n",
    "- Alone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a9ae70",
   "metadata": {},
   "source": [
    "Candidates contain no nulls, continuing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95d34578",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set original subsets to enable rerun of following cells without notebook restart ###\n",
    "train_original = train.copy()\n",
    "validate_original = validate.copy()\n",
    "test_original = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10ee62e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>pclass</th>\n",
       "      <th>alone</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>20.5250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>39.6875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  sex  pclass  alone     fare\n",
       "583         0    0       1      1  40.1250\n",
       "165         1    0       3      0  20.5250\n",
       "50          0    0       3      0  39.6875"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Set features, prepare for model ###\n",
    "train, validate, test = train_original.copy(), validate_original.copy(), test_original.copy()\n",
    "\n",
    "train = train[['survived','sex','pclass','alone','fare']]\n",
    "validate = validate[['survived','sex','pclass','alone','fare']]\n",
    "test = test[['survived','sex','pclass','alone','fare']]\n",
    "\n",
    "map1 = {'male':0, 'female':1}\n",
    "train['sex'] = train.sex.map(map1)\n",
    "validate['sex'] = validate.sex.map(map1)\n",
    "test['sex'] = test.sex.map(map1)\n",
    "\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1de14a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set target ###\n",
    "X_train, y_train = train.drop(columns='survived'), train.survived\n",
    "X_validate, y_validate = validate.drop(columns='survived'), validate.survived\n",
    "X_test, y_test = test.drop(columns='survived'), test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1475fd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Decision Tree Model ###\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=123)\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e94e0bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8232931726907631\n"
     ]
    }
   ],
   "source": [
    "### Show score, make predictions ###\n",
    "print(\"Score:\", clf.score(X_train, y_train))\n",
    "y_pred = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "587d453c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[276  31]\n",
      " [ 57 134]] \n",
      "\n",
      "Classification Report\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.828829    0.812121  0.823293    0.820475      0.822421\n",
      "recall       0.899023    0.701571  0.823293    0.800297      0.823293\n",
      "f1-score     0.862500    0.752809  0.823293    0.807654      0.820430\n",
      "support    307.000000  191.000000  0.823293  498.000000    498.000000\n"
     ]
    }
   ],
   "source": [
    "### Print confusion matrix and classification report ###\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_train, y_pred), \"\\n\")\n",
    "\n",
    "print(\"Classification Report\")\n",
    "report = pd.DataFrame(classification_report(y_train, y_pred, output_dict=True))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "565ea7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7991967871485943 \n",
      "\n",
      "Confusion Matrix\n",
      "[[265  42]\n",
      " [ 58 133]] \n",
      "\n",
      "Classification Report\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.820433    0.760000  0.799197    0.790217      0.797255\n",
      "recall       0.863192    0.696335  0.799197    0.779764      0.799197\n",
      "f1-score     0.841270    0.726776  0.799197    0.784023      0.797358\n",
      "support    307.000000  191.000000  0.799197  498.000000    498.000000\n"
     ]
    }
   ],
   "source": [
    "### Try a model with different max_depth ###\n",
    "clf_alt = DecisionTreeClassifier(max_depth=1, random_state=123)\n",
    "clf_alt = clf_alt.fit(X_train, y_train)\n",
    "\n",
    "print(\"Score:\", clf_alt.score(X_train, y_train), \"\\n\")\n",
    "y_pred_alt = clf_alt.predict(X_train)\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_train, y_pred_alt), \"\\n\")\n",
    "\n",
    "print(\"Classification Report\")\n",
    "report = pd.DataFrame(classification_report(y_train, y_pred_alt, output_dict=True))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10aa0da",
   "metadata": {},
   "source": [
    "Model 1 score (max_depth=3): 82.3% ----- Model 2 score (max_depth=1): 79.9%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d285ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 score: 0.7850467289719626\n",
      "Model 2 score: 0.7616822429906542\n"
     ]
    }
   ],
   "source": [
    "### Run models against out-of-sample data ###\n",
    "print(\"Model 1 score:\", clf.score(X_validate, y_validate))\n",
    "print(\"Model 2 score:\", clf_alt.score(X_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af96bd6b",
   "metadata": {},
   "source": [
    "## Telco Data - Decision Tree\n",
    "Repeat the same steps as above with this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f240a150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['customerID', 'gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
      "       'tenure', 'PhoneService', 'MultipleLines', 'InternetService',\n",
      "       'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
      "       'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n",
      "       'PaymentMethod', 'MonthlyCharges', 'TotalCharges', 'Churn'],\n",
      "      dtype='object')\n",
      "customerID           object\n",
      "gender               object\n",
      "SeniorCitizen         int64\n",
      "Partner              object\n",
      "Dependents           object\n",
      "tenure                int64\n",
      "PhoneService         object\n",
      "MultipleLines        object\n",
      "InternetService      object\n",
      "OnlineSecurity       object\n",
      "OnlineBackup         object\n",
      "DeviceProtection     object\n",
      "TechSupport          object\n",
      "StreamingTV          object\n",
      "StreamingMovies      object\n",
      "Contract             object\n",
      "PaperlessBilling     object\n",
      "PaymentMethod        object\n",
      "MonthlyCharges      float64\n",
      "TotalCharges        float64\n",
      "Churn                object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
       "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
       "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
       "\n",
       "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
       "0  No phone service             DSL             No  ...               No   \n",
       "1                No             DSL            Yes  ...              Yes   \n",
       "2                No             DSL            Yes  ...               No   \n",
       "\n",
       "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
       "0          No          No              No  Month-to-month              Yes   \n",
       "1          No          No              No        One year               No   \n",
       "2          No          No              No  Month-to-month              Yes   \n",
       "\n",
       "      PaymentMethod MonthlyCharges  TotalCharges  Churn  \n",
       "0  Electronic check          29.85         29.85     No  \n",
       "1      Mailed check          56.95       1889.50     No  \n",
       "2      Mailed check          53.85        108.15    Yes  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Pull in Telco dataset ###\n",
    "telco = pd.read_csv('Cust_Churn_Telco.csv')\n",
    "print(telco.columns)\n",
    "print(telco.dtypes)\n",
    "telco.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8d9505e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save a copy before manipulations ###\n",
    "telco_original = telco.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8249b87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convert Yes and No to 1 and 0, respectively ###\n",
    "telco = telco_original.copy()\n",
    "map1 = {\"No\":0, \"Yes\":1}\n",
    "telco['Churn'] = telco.Churn.map(map1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8075dae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customerID          0\n",
       "gender              0\n",
       "SeniorCitizen       0\n",
       "Partner             0\n",
       "Dependents          0\n",
       "tenure              0\n",
       "PhoneService        0\n",
       "MultipleLines       0\n",
       "InternetService     0\n",
       "OnlineSecurity      0\n",
       "OnlineBackup        0\n",
       "DeviceProtection    0\n",
       "TechSupport         0\n",
       "StreamingTV         0\n",
       "StreamingMovies     0\n",
       "Contract            0\n",
       "PaperlessBilling    0\n",
       "PaymentMethod       0\n",
       "MonthlyCharges      0\n",
       "TotalCharges        0\n",
       "Churn               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Null Handling ###\n",
    "# telco.isna().sum()\n",
    "telco['TotalCharges'] = telco.TotalCharges.fillna(value=(telco.tenure * telco.MonthlyCharges))\n",
    "telco.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f81b6e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3943, 21), (1691, 21), (1409, 21))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Split data with target = churn ###\n",
    "train_validate, test = train_test_split(telco, test_size=.2, \n",
    "                                            random_state=123, \n",
    "                                            stratify=telco.Churn)\n",
    "train, validate = train_test_split(train_validate, test_size=.3,\n",
    "                                                   random_state=123,\n",
    "                                                   stratify=train_validate.Churn)\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5078e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7347197565305605"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Baseline and Baseline Prediction ###\n",
    "# train.Churn.value_counts()\n",
    "(train.Churn == 0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c25ca5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bivariate Exploration setup ###\n",
    "cat_vars = ['Contract','gender','SeniorCitizen','Partner','Dependents','PhoneService','MultipleLines','InternetService',\n",
    "           'OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies','Contract',\n",
    "           'PaperlessBilling','PaymentMethod']\n",
    "quant_vars = ['tenure','MonthlyCharges','TotalCharges']\n",
    "target = 'Churn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "414fe732",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Explore! ###\n",
    "# explore.explore_bivariate(train, target, cat_vars, quant_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8614ab8",
   "metadata": {},
   "source": [
    "Candidates (Requires further analysis):\n",
    "- Partner: (No=35%churn, Yes=18%churn with even populations)\n",
    "- Dependents: (No=32%churn, Yes=15%churn at 2to1)\n",
    "- InternetService (DSL=20%churn, Fiber=42%churn, None=8%churn where Fiber is nearly half of total population)\n",
    "- OnlineBackup (No=40%, 20%, 7% where No is nearly half of total population)\n",
    "- DeviceProtection (nearly same population and proportions as OnlineBackup... don't include?)\n",
    "- TechSupport (18, 7, No=41% where No is nearly half of population)\n",
    "- Contract (10, 3, m2m=42% where m2m is more than half of population)\n",
    "- PaperlessBilling (18, Yes=32% where Yes is 2/5ths of population)\n",
    "- PaymentMethod (18, 18, eCheck=42%, 18 where eCheck is 1/3rd of population)\n",
    "\n",
    "Not Candidates (and why):\n",
    "- Gender: No significant difference in churn rate\n",
    "- PhoneService: No significant difference in churn rate\n",
    "- MultipleLines: Not a very significant difference in churn rate\n",
    "- Senior Citizen: Small population compared to total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08bfdb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5282685512367491 0.5753828032979976 0.571849234393404 0.6955241460541813 0.5053501945525292 0.5214007782101168 0.6960116731517509 0.6493135011441648 0.744279176201373 0.6281818181818182\n"
     ]
    }
   ],
   "source": [
    "### In-Common Populations ###\n",
    "\n",
    "# Goal: For the features whose high-churning value is nearly 50% of total population,\n",
    "#       determine if any two have too many values in common to be added to the model.\n",
    "\n",
    "# Features to investigate: Partner(Single), InternetService(Fiber), OnlineBackup(Nobackup), \n",
    "#                          DeviceProtection(Unprotected), Contract(Month-to-month)\n",
    "\n",
    "fs = (train[train.InternetService == 'Fiber optic'].Partner == 'No').mean()\n",
    "fn = (train[train.InternetService == 'Fiber optic'].OnlineBackup == 'No').mean()\n",
    "fu = (train[train.InternetService == 'Fiber optic'].DeviceProtection == 'No').mean()\n",
    "fm = (train[train.InternetService == 'Fiber optic'].Contract == 'Month-to-month').mean()\n",
    "\n",
    "sn = (train[train.Partner == 'No'].OnlineBackup == 'No').mean()\n",
    "su = (train[train.Partner == 'No'].DeviceProtection == 'No').mean()\n",
    "sm = (train[train.Partner == 'No'].Contract == 'Month-to-month').mean()\n",
    "\n",
    "nu = (train[train.OnlineBackup == 'No'].DeviceProtection == 'No').mean()\n",
    "nm = (train[train.OnlineBackup == 'No'].Contract == 'Month-to-month').mean()\n",
    "\n",
    "mu = (train[train.Contract == 'Month-to-month'].DeviceProtection == 'No').mean()\n",
    "\n",
    "# Print percent-in-common for each two-feature combination\n",
    "print(fs, fn, fu, fm, sn, su, sm, nu, nm, mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944fd4a3",
   "metadata": {},
   "source": [
    "Populations:\n",
    "- 50s% Share: Single-Nobackup (50.5%), Single-Unprotected (52.1%), Fiber-Single (52.8%), Fiber-Unprotected (57.1%), Fiber-Nobackup (57.5%)\n",
    "- 60s% Share: Monthly-Unprotected (62.8%), Nobackup-Unprotected (64.9%), Fiber-Monthly (69.55%), Single_Monthly (69.6%)\n",
    "- 70s% Share: Nobackup-Monthly (74.4%)\n",
    "\n",
    "Takeaways: \n",
    "- **Will not include Contract (Month-to-month) in model, it adds redundancy compared to other features.**\n",
    "- **Will not include DeviceProtection (Unprotected) in model, it shares a large proportion of population with OnlineBackup (Nobackup).**\n",
    "\n",
    "Model Target and Features:\n",
    "- Target: Churn\n",
    "- Features: Partner, InternetService, OnlineBackup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "648f1e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3943, 4), (1691, 4), (1409, 4))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Set features and target ###\n",
    "# train = train[['Churn','Contract','InternetService','Partner','OnlineBackup']]\n",
    "# validate = validate[['Churn','Contract','InternetService','Partner','OnlineBackup']]\n",
    "# test = test[['Churn','Contract','InternetService','Partner','OnlineBackup']]\n",
    "\n",
    "train = train[['Churn','InternetService','Partner','OnlineBackup']]\n",
    "validate = validate[['Churn','InternetService','Partner','OnlineBackup']]\n",
    "test = test[['Churn','InternetService','Partner','OnlineBackup']]\n",
    "\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23f90b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>Partner</th>\n",
       "      <th>OnlineBackup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5262</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3734</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4340</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Churn  InternetService  Partner  OnlineBackup\n",
       "5262      0                0        0             0\n",
       "3734      0                1        0             1\n",
       "4340      0                0        0             0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Encode data subsets for model ###\n",
    "# map0 = {'Month-to-month':0, 'One year':1, 'Two year':2}\n",
    "map1 = {'DSL':0, 'Fiber optic':1, 'No':2}\n",
    "map2 = {'No':0, 'Yes': 1}\n",
    "map3 = {'No':0, 'Yes':1, 'No internet service':2}\n",
    "\n",
    "for dataset in [train, validate, test]:\n",
    "#    dataset['Contract'] = dataset.Contract.map(map0)\n",
    "    dataset['InternetService'] = dataset.InternetService.map(map1)\n",
    "    dataset['Partner'] = dataset.Partner.map(map2)\n",
    "    dataset['OnlineBackup'] = dataset.OnlineBackup.map(map3)\n",
    "\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5028d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split out target ###\n",
    "X_train, y_train = train.drop(columns='Churn'), train.Churn\n",
    "X_validate, y_validate = validate.drop(columns='Churn'), validate.Churn\n",
    "X_test, y_test = test.drop(columns='Churn'), test.Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77780756",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Decision Tree Model ###\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=123)\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f530f22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7565305604869389\n"
     ]
    }
   ],
   "source": [
    "### Show score, make predictions ###\n",
    "print(\"Score:\", clf.score(X_train, y_train))\n",
    "y_pred = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fda775d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[2649  248]\n",
      " [ 712  334]] \n",
      "\n",
      "Classification Report\n",
      "                     0            1  accuracy    macro avg  weighted avg\n",
      "precision     0.788158     0.573883  0.756531     0.681021      0.731315\n",
      "recall        0.914394     0.319312  0.756531     0.616853      0.756531\n",
      "f1-score      0.846596     0.410319  0.756531     0.628458      0.730861\n",
      "support    2897.000000  1046.000000  0.756531  3943.000000   3943.000000\n"
     ]
    }
   ],
   "source": [
    "### Print confusion matrix and classification report ###\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_train, y_pred), \"\\n\")\n",
    "\n",
    "print(\"Classification Report\")\n",
    "report = pd.DataFrame(classification_report(y_train, y_pred, output_dict=True))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f7f4648c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7347197565305605 \n",
      "\n",
      "Confusion Matrix\n",
      "[[2897    0]\n",
      " [1046    0]] \n",
      "\n",
      "Classification Report\n",
      "                     0       1  accuracy    macro avg  weighted avg\n",
      "precision     0.734720     0.0   0.73472     0.367360      0.539813\n",
      "recall        1.000000     0.0   0.73472     0.500000      0.734720\n",
      "f1-score      0.847076     0.0   0.73472     0.423538      0.622363\n",
      "support    2897.000000  1046.0   0.73472  3943.000000   3943.000000\n"
     ]
    }
   ],
   "source": [
    "### Try a model with different max_depth ###\n",
    "clf_alt = DecisionTreeClassifier(max_depth=1, random_state=123)\n",
    "clf_alt = clf_alt.fit(X_train, y_train)\n",
    "\n",
    "print(\"Score:\", clf_alt.score(X_train, y_train), \"\\n\")\n",
    "y_pred_alt = clf_alt.predict(X_train)\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_train, y_pred_alt), \"\\n\")\n",
    "\n",
    "print(\"Classification Report\")\n",
    "report = pd.DataFrame(classification_report(y_train, y_pred_alt, output_dict=True))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3fa77729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 in-sample score: 0.7565\n",
      "Model 1 out-of-sample score: 0.7504\n",
      "Model 1 test score: 0.7473 \n",
      "\n",
      "Model 2 in-sample score: 0.7347\n",
      "Model 2 out-of-sample score: 0.7345\n",
      "Model 2 test score: 0.7346\n"
     ]
    }
   ],
   "source": [
    "### Run models against out-of-sample data ###\n",
    "print(\"Model 1 in-sample score:\", round(clf.score(X_train, y_train),4))\n",
    "print(\"Model 1 out-of-sample score:\", round(clf.score(X_validate, y_validate),4))\n",
    "print(\"Model 1 test score:\", round(clf.score(X_test, y_test),4), \"\\n\")\n",
    "\n",
    "print(\"Model 2 in-sample score:\", round(clf_alt.score(X_train, y_train),4))\n",
    "print(\"Model 2 out-of-sample score:\", round(clf_alt.score(X_validate, y_validate),4))\n",
    "print(\"Model 2 test score:\", round(clf_alt.score(X_test, y_test),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0d3601",
   "metadata": {},
   "source": [
    "### Model 1 Performance\n",
    "\n",
    "**Includes Contract**\n",
    "- Model 1 in-sample score: 0.7695\n",
    "- Model 1 out-of-sample score: 0.7564\n",
    "- Model 1 test score: 0.7502 \n",
    "\n",
    "**Doesn't Include Contract**\n",
    "- Model 1 in-sample score: 0.7565\n",
    "- Model 1 out-of-sample score: 0.7504\n",
    "- Model 1 test score: 0.7473 \n",
    "\n",
    "\n",
    "\n",
    "### Model 2 Performance\n",
    "\n",
    "**Includes Contract**\n",
    "- Model 2 in-sample score: 0.7347\n",
    "- Model 2 out-of-sample score: 0.7345\n",
    "- Model 2 test score: 0.7346\n",
    "\n",
    "**Doesn't Include Contract**\n",
    "- Model 2 in-sample score: 0.7347\n",
    "- Model 2 out-of-sample score: 0.7345\n",
    "- Model 2 test score: 0.7346"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2601533",
   "metadata": {},
   "source": [
    "## Titanic Data - Random Forest\n",
    "- Fit the Random Forest classifier to your training sample using min_samples_leaf = 1, max_depth=10, and random_state.\n",
    "- Make predictions.\n",
    "- Evaluate results using model score, confusion matrix, and classification report.\n",
    "- Create new model(s) with increased min_samples_leaf and decreased max_depth.\n",
    "- What are the differences in the evaluation metrics? \n",
    "- Which performs better on your in-sample data? Why?\n",
    "- After making a few models, which one has the best performance (or closest metrics) on both train and validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7616092e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "\n",
       "  embarked  class  deck  embark_town  alone  \n",
       "0        S  Third  None  Southampton      0  \n",
       "1        C  First     C    Cherbourg      0  \n",
       "2        S  Third  None  Southampton      1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Checking dataframe ###\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "72a88772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((498, 13), (214, 13), (179, 13))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Split data ###\n",
    "train_validate, test = train_test_split(df, test_size=.2, \n",
    "                                            random_state=123, \n",
    "                                            stratify=df.survived)\n",
    "train, validate = train_test_split(train_validate, test_size=.3,\n",
    "                                                   random_state=123,\n",
    "                                                   stratify=train_validate.survived)\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc675c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>pclass</th>\n",
       "      <th>alone</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>20.5250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>39.6875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  sex  pclass  alone     fare\n",
       "583         0    0       1      1  40.1250\n",
       "165         1    0       3      0  20.5250\n",
       "50          0    0       3      0  39.6875"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Set features, prepare for model ###\n",
    "train, validate, test = train_original.copy(), validate_original.copy(), test_original.copy()\n",
    "\n",
    "train = train[['survived','sex','pclass','alone','fare']]\n",
    "validate = validate[['survived','sex','pclass','alone','fare']]\n",
    "test = test[['survived','sex','pclass','alone','fare']]\n",
    "\n",
    "map1 = {'male':0, 'female':1}\n",
    "train['sex'] = train.sex.map(map1)\n",
    "validate['sex'] = validate.sex.map(map1)\n",
    "test['sex'] = test.sex.map(map1)\n",
    "\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0146dd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set target ###\n",
    "X_train, y_train = train.drop(columns='survived'), train.survived\n",
    "X_validate, y_validate = validate.drop(columns='survived'), validate.survived\n",
    "X_test, y_test = test.drop(columns='survived'), test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58d0c6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Random Forest Model ###\n",
    "rf = RandomForestClassifier(min_samples_leaf=1, max_depth=10, random_state=123)\n",
    "rf = rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2db6b682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9337349397590361\n"
     ]
    }
   ],
   "source": [
    "### Show score, make predictions ###\n",
    "print(\"Score:\", rf.score(X_train, y_train))\n",
    "y_pred = rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a7481ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[301   6]\n",
      " [ 27 164]] \n",
      "\n",
      "Classification Report\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.917683    0.964706  0.933735    0.941194      0.935718\n",
      "recall       0.980456    0.858639  0.933735    0.919547      0.933735\n",
      "f1-score     0.948031    0.908587  0.933735    0.928309      0.932903\n",
      "support    307.000000  191.000000  0.933735  498.000000    498.000000\n"
     ]
    }
   ],
   "source": [
    "### Print confusion matrix and classification report ###\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_train, y_pred), \"\\n\")\n",
    "\n",
    "print(\"Classification Report\")\n",
    "report = pd.DataFrame(classification_report(y_train, y_pred, output_dict=True))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "455c4d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Increase min_samples_leaf, decrease max_depth in new model ###\n",
    "rf_alt = RandomForestClassifier(min_samples_leaf=5, max_depth=5)\n",
    "rf_alt = rf_alt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "38d20751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8514056224899599\n"
     ]
    }
   ],
   "source": [
    "### Show score, make predictions ###\n",
    "print(\"Score:\", rf_alt.score(X_train, y_train))\n",
    "y_pred_alt = rf_alt.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a1c7b614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[291  16]\n",
      " [ 58 133]] \n",
      "\n",
      "Classification Report\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.833811    0.892617  0.851406    0.863214      0.856365\n",
      "recall       0.947883    0.696335  0.851406    0.822109      0.851406\n",
      "f1-score     0.887195    0.782353  0.851406    0.834774      0.846985\n",
      "support    307.000000  191.000000  0.851406  498.000000    498.000000\n"
     ]
    }
   ],
   "source": [
    "### Print confusion matrix and classification report ###\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_train, y_pred_alt), \"\\n\")\n",
    "\n",
    "print(\"Classification Report\")\n",
    "report = pd.DataFrame(classification_report(y_train, y_pred_alt, output_dict=True))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79404ec9",
   "metadata": {},
   "source": [
    "Higher min_samples_leaf and lower max_depth makes for worse in-sample accuracy because a lower max_depth means every tree in the random forest is less extensive and a higher min_samples_leaf means every sample is more restricted (performs worse)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "42212e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 in-sample score: 0.9337349397590361\n",
      "Model 1 out-of-sample score: 0.794392523364486 \n",
      "\n",
      "Model 2 in-sample score: 0.8514056224899599\n",
      "Model 2 out-of-sample score: 0.780373831775701\n"
     ]
    }
   ],
   "source": [
    "### Run models against out-of-sample data ###\n",
    "print(\"Model 1 in-sample score:\", rf.score(X_train, y_train))\n",
    "print(\"Model 1 out-of-sample score:\", rf.score(X_validate, y_validate), \"\\n\")\n",
    "\n",
    "print(\"Model 2 in-sample score:\", rf_alt.score(X_train, y_train))\n",
    "print(\"Model 2 out-of-sample score:\", rf_alt.score(X_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46243fe9",
   "metadata": {},
   "source": [
    "Even though the Random Forest with min_samples_leaf=1 and max_depth=10 performed better on the in-sample data, it was clearly much more overfit than the less-extensive, more-restricted Random Forest having min_samples_leaf=5 and max_depth=5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e06f555",
   "metadata": {},
   "source": [
    "## Titanic Data - K-Nearest Neighbors\n",
    "\n",
    "- Fit a K-Nearest Neighbors classifier to your training sample.\n",
    "- Make predictions.\n",
    "- Evaluate your results using the model score, confusion matrix, and classification report.\n",
    "- Make new model with k=10.\n",
    "- Make another new model with k=20.\n",
    "- What are the differences in the evaluation metrics?\n",
    "- Which performs better on your in-sample data? Why?\n",
    "- Which model performs best on our out-of-sample data from validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "93339397",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fit KNN to training data ###\n",
    "knn = KNeighborsClassifier()\n",
    "knn = knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9c95580f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make predictions ###\n",
    "y_pred = knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d379c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8112449799196787\n",
      "Confusion Matrix\n",
      " [[262  45]\n",
      " [ 49 142]]\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.842444    0.759358  0.811245    0.800901      0.810578\n",
      "recall       0.853420    0.743455  0.811245    0.798438      0.811245\n",
      "f1-score     0.847896    0.751323  0.811245    0.799610      0.810857\n",
      "support    307.000000  191.000000  0.811245  498.000000    498.000000\n"
     ]
    }
   ],
   "source": [
    "### Score, confusion matric, classification report ###\n",
    "print(\"Score:\", knn.score(X_train, y_train))\n",
    "print(\"Confusion Matrix\\n\", confusion_matrix(y_train, y_pred))\n",
    "print(pd.DataFrame(classification_report(y_train, y_pred, output_dict=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5c583ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.785140562248996\n",
      "Confusion Matrix\n",
      " [[262  45]\n",
      " [ 62 129]]\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.808642    0.741379  0.785141    0.775011      0.782844\n",
      "recall       0.853420    0.675393  0.785141    0.764406      0.785141\n",
      "f1-score     0.830428    0.706849  0.785141    0.768639      0.783031\n",
      "support    307.000000  191.000000  0.785141  498.000000    498.000000\n"
     ]
    }
   ],
   "source": [
    "### Make new model with k=10, make predictions, print metrics ###\n",
    "knn_10 = KNeighborsClassifier(n_neighbors=10)\n",
    "knn_10 = knn_10.fit(X_train, y_train)\n",
    "y_pred10 = knn_10.predict(X_train)\n",
    "\n",
    "print(\"Score:\", knn_10.score(X_train, y_train))\n",
    "print(\"Confusion Matrix\\n\", confusion_matrix(y_train, y_pred10))\n",
    "print(pd.DataFrame(classification_report(y_train, y_pred10, output_dict=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1fb7f845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7469879518072289\n",
      "Confusion Matrix\n",
      " [[257  50]\n",
      " [ 76 115]]\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.771772    0.696970  0.746988    0.734371      0.743083\n",
      "recall       0.837134    0.602094  0.746988    0.719614      0.746988\n",
      "f1-score     0.803125    0.646067  0.746988    0.724596      0.742888\n",
      "support    307.000000  191.000000  0.746988  498.000000    498.000000\n"
     ]
    }
   ],
   "source": [
    "### Make new model with k=20, make predictions, print metrics ###\n",
    "knn_20 = KNeighborsClassifier(n_neighbors=20)\n",
    "knn_20 = knn_20.fit(X_train, y_train)\n",
    "y_pred20 = knn_20.predict(X_train)\n",
    "\n",
    "print(\"Score:\", knn_20.score(X_train, y_train))\n",
    "print(\"Confusion Matrix\\n\", confusion_matrix(y_train, y_pred20))\n",
    "print(pd.DataFrame(classification_report(y_train, y_pred20, output_dict=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d115802e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=5 in-sample score: 0.8112449799196787\n",
      "K=5 out-of-sample score: 0.7663551401869159 \n",
      "\n",
      "K=10 in-sample score: 0.785140562248996\n",
      "K=10 out-of-sample score: 0.7383177570093458 \n",
      "\n",
      "K=20 in-sample score: 0.7469879518072289\n",
      "K=20 out-of-sample score: 0.6915887850467289\n"
     ]
    }
   ],
   "source": [
    "### Run models against out-of-sample data ###\n",
    "print(\"K=5 in-sample score:\", knn.score(X_train, y_train))\n",
    "print(\"K=5 out-of-sample score:\", knn.score(X_validate, y_validate), \"\\n\")\n",
    "\n",
    "print(\"K=10 in-sample score:\", knn_10.score(X_train, y_train))\n",
    "print(\"K=10 out-of-sample score:\", knn_10.score(X_validate, y_validate), \"\\n\")\n",
    "\n",
    "print(\"K=20 in-sample score:\", knn_20.score(X_train, y_train))\n",
    "print(\"K=20 out-of-sample score:\", knn_20.score(X_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7db5b3",
   "metadata": {},
   "source": [
    "As n_nearest increased, each model's in-sample and out-of-sample score decreased. Additionally, each model performed roughly 5% more accurately on in-sample compared to out-of-sample, indicating a potential need to revise what data will be used to train the model (may need to change/add features for fit)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073b72a2",
   "metadata": {},
   "source": [
    "## Titanic Data - Logistic Regression\n",
    "1. Calculate baseline for Titanic data, set threshold for future model accuracy.\n",
    "2. Create a model for age, fare, and pclass, then compare to the baseline.\n",
    "3. Create a new model that also includes sex.\n",
    "4. Create multiple models with varying features, keep the best 3 for train and validate data.\n",
    "5. Use the best model of the three for the test data, compare performance to train/validate.\n",
    "6. BONUS1: How do different strategies for handling the missing values in the age column affect model performance?\n",
    "7. BONUS2: How do different strategies for encoding sex affect model performance?\n",
    "8. BONUS3:\n",
    "- scikit-learn's LogisticRegression classifier is actually applying a regularization penalty to the coefficients by default. This penalty causes the magnitude of the coefficients in the resulting model to be smaller than they otherwise would be. This value can be modified with the C hyper parameter. Small values of C correspond to a larger penalty, and large values of C correspond to a smaller penalty.\n",
    "- Try out the following values for C and note how the coefficients and the model's performance on both the dataset it was trained on and on the validate split are affected.\n",
    "<code>C=.01,.1,1,10,100,1000</code>\n",
    "9. BONUS4: How does scaling the data interact with your choice of C?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c01aedae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Performance: 0.6162\n"
     ]
    }
   ],
   "source": [
    "### Calculate baseline ###\n",
    "df = df_original.copy()\n",
    "baseline = df.groupby('survived').survived.count().idxmax()\n",
    "print('Baseline Performance:', round((df.survived == 0).mean(),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5a41d028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Performance: 0.6162\n",
      "Model Performance: 0.7028\n"
     ]
    }
   ],
   "source": [
    "### Create model for age, fare, and pclass, then compare to the baseline ###\n",
    "# Handle nulls\n",
    "df['age'] = df.age.fillna(value=int(df.age.mean()))\n",
    "most_freq_embarked = df.groupby('embark_town').embark_town.count().idxmax()\n",
    "df['embark_town'] = df.embark_town.fillna(value=most_freq_embarked)\n",
    "df = df.drop(columns=['deck','embarked','class','passenger_id'])\n",
    "\n",
    "# Encode values\n",
    "map0 = {'male':0, 'female':1}\n",
    "map1 = {'Cherbourg':0, 'Southampton':1, 'Queenstown':2}\n",
    "df['sex'] = df.sex.map(map0)\n",
    "df['embark_town'] = df.embark_town.map(map1)\n",
    "\n",
    "# Split\n",
    "train_validate, test = train_test_split(df, test_size=.2, \n",
    "                                            random_state=123, \n",
    "                                            stratify=df.survived)\n",
    "train, validate = train_test_split(train_validate, test_size=.3,\n",
    "                                                   random_state=123,\n",
    "                                                   stratify=train_validate.survived)\n",
    "\n",
    "# Limit columns\n",
    "train_1 = train[['survived','age','fare','pclass']]\n",
    "validate_1 = validate[['survived','age','fare','pclass']]\n",
    "test_1 = test[['survived','age','fare','pclass']]\n",
    "\n",
    "# Isolate target\n",
    "X_train, y_train = train_1.drop(columns='survived'), train_1.survived\n",
    "X_validate, y_validate = validate_1.drop(columns='survived'), validate_1.survived\n",
    "X_test, y_test = test_1.drop(columns='survived'), test_1.survived\n",
    "\n",
    "# Create, fit model\n",
    "logit = LogisticRegression(random_state=123)\n",
    "logit = logit.fit(X_train, y_train)\n",
    "\n",
    "# Score model, compare baseline\n",
    "print('Baseline Performance:', round((df.survived == 0).mean(),4))\n",
    "print('Model Performance:', round(logit.score(X_train, y_train),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f7a76a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Performance: 0.6162\n",
      "Model Performance: 0.8153\n"
     ]
    }
   ],
   "source": [
    "### Create new model including sex ###\n",
    "# Set columns of already-split data\n",
    "train_2 = train[['survived','age','fare','pclass','sex']]\n",
    "validate_2 = validate[['survived','age','fare','pclass','sex']]\n",
    "test_2 = test[['survived','age','fare','pclass','sex']]\n",
    "\n",
    "# Isolate target\n",
    "X_train, y_train = train_2.drop(columns='survived'), train_2.survived\n",
    "X_validate, y_validate = validate_2.drop(columns='survived'), validate_2.survived\n",
    "X_test, y_test = test_2.drop(columns='survived'), test_2.survived\n",
    "\n",
    "# Create, fit model\n",
    "logit = LogisticRegression(random_state=123)\n",
    "logit = logit.fit(X_train, y_train)\n",
    "\n",
    "# Score model, compare baseline\n",
    "print('Baseline Performance:', round((df.survived == 0).mean(),4))\n",
    "print('Model Performance:', round(logit.score(X_train, y_train),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "742bec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create multiple models with various features, keep best 3 ###\n",
    "# Use full df, isolate target\n",
    "X_train, y_train = train.drop(columns='survived'), train.survived\n",
    "X_validate, y_validate = validate.drop(columns='survived'), validate.survived\n",
    "X_test, y_test = test.drop(columns='survived'), test.survived\n",
    "\n",
    "# Create Random Forest model, fit, and print feature importances\n",
    "rf = RandomForestClassifier(max_depth=10, random_state=123)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "features = pd.DataFrame(index=X_train.columns)\n",
    "features['importances'] = rf.feature_importances_\n",
    "# print(features.T)\n",
    "\n",
    "# Use top 5 features based on importances\n",
    "X_train = X_train[['sex','fare','age','pclass','sibsp']]\n",
    "X_validate = X_validate[['sex','fare','age','pclass','sibsp']]\n",
    "X_test = X_test[['sex','fare','age','pclass','sibsp']]\n",
    "\n",
    "# Create and score multiple Logistic Regression models\n",
    "metrics = []\n",
    "models = []\n",
    "for i in np.arange(0.1, 1, 0.1):\n",
    "    C_value = i\n",
    "    logit = LogisticRegression(C=C_value, random_state=123)\n",
    "    logit = logit.fit(X_train, y_train)\n",
    "    in_sample_score = logit.score(X_train, y_train)\n",
    "    out_of_sample_score = logit.score(X_validate, y_validate)\n",
    "    output = {\n",
    "        \"C_value\": i,\n",
    "        \"train_score\": in_sample_score,\n",
    "        \"validate_score\": out_of_sample_score\n",
    "    } \n",
    "    metrics.append(output)\n",
    "    models.append(logit)\n",
    "\n",
    "# Print scores\n",
    "metrics = pd.DataFrame(metrics)\n",
    "# print(metrics)\n",
    "\n",
    "# Using C=0.2, C=0.3, C=0.4 as top-3\n",
    "logit1, logit2, logit3 = models[1], models[2], models[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "081f7bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.8012\n",
      "Validate score: 0.7617\n",
      "Test score: 0.7877\n"
     ]
    }
   ],
   "source": [
    "### Use best model for train/validate on test data ###\n",
    "# Top performing model is C=0.3\n",
    "print('Train score:', round(logit2.score(X_train, y_train),4))\n",
    "print('Validate score:', round(logit2.score(X_validate, y_validate),4))\n",
    "print('Test score:', round(logit2.score(X_test, y_test),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf82567",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
